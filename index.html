<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <title>Falx Artifact</title>

  <link rel="stylesheet" href="static/index.css">
  <link rel="stylesheet" href="static/github-light.css">
  <meta name="viewport" content="width=device-width">
</head>
<body>
  <div class="wrapper">
    <header>
      <h1>Visualization By Example</h1>
      <h3 class="subtitle">Chenglong Wang, Yu Feng, Ras Bodik, Alvin Cheung, Isil Dillig </h3>
    </header>

    <section>
      <p>This page hosts the artifact for our POPL 2020 submission, <a href="popl20_draft.pdf"><i>Visualization By Example (draft)</i></a>.
      </p>

      <h2>Materials</h2>

      <p>Our artifact <a class='small_link' href="falx_artifact.tar.gz">[falx_artifact.tar.gz]</a> contains the following materials: </p>

      <ul> 
        <li> <i>Benchmarks</i> of visualization by example benchmarks.</li>
        <li> <i>Implementation of the synthesis algorithm</i> (named <span style="font-weight:bold;">Falx</span>) in Python.</li>
        <li> <i>Evaluation log and analysis scripts</i> used in our paper evaluation.</li>
      </ul>

      <h2>Prerequisite</h2>

      <p>Our experiments run in Docker, instructions to install Docker can be found <a href="https://docs.docker.com/install/">here</a>.</p>

      <p>After the docker is install, run the following command to create and enter the Docker container that would be used for artifat evaluation. This command will download the docker image, build the docker container, and finally enter the docker container.</p>

      <pre>sh ./init_docker.sh</pre>

      <p>Once in the docker, run the following commands to install dependencies. These commands install python dependencies of our tool, and configure the R environment that is needed to interpret table transformation programs. Note that configuring R environments can take a while (up to 20 minutes).</p>

      <pre>cd /falx-popl-snapshot/artifact
pip3 install -r requirements
pip3 install -e .
echo "install.packages(\"dplyr\", dependencies=TRUE); install.packages(\"tidyr\", dependencies=TRUE);install.packages(\"jsonlite\", dependencies=TRUE);install.packages(\"compare\", dependencies=TRUE)" | R --save</pre>

      <p>In a rare event that your docker building process get broken, you can (1) delete the docker container using command <code>docker rm CONTAINER_ID</code>, where <code>CONTAINER_ID</code> of the docker you just built can be looked up with command <code>docker ps -a</code>  (look for the container built from an image named <code>falx-artifact-img</code>) and (2) delete the the docker image (with command <code>docker rmi falx-artifact-img</code>), and then start over from the first step.</p>

      <h2>Overview</h2>

      <p>
        Our implementation of the visualization synthesizer includes three main modules: (1) the implementation of the visualization language interpreter that interprets a Vega-Lite script into visualization trace (<a href="falx-popl-snapshot/falx/chart.py">link</a>), (2) an R table transformation language interpreter built on top of R tydiverse library (<a href="falx-popl-snapshot/falx/morpheus.py">link</a>), and (3) a bidirectional synthesizer that synthesizes visualization scripts from input data and partial visual trace, which is built on top of the Z3 SMT solver. We also include implementations of the baseline in our artifact to reproduce results in the paper.
      </p>

      <p>
        In the following, we first present benchmarks we used in our evaluation, then show instructions to reproduce our experiments described in the paper (Section 6), and finally how to use our the tool to solve new visualization tasks. 
      </p>

      <h2>Benchmarks</h2>

      <p>In our AutoVis benchmarks, each visual sketch comes with an input data. Given the <span style="text-decoration: underline;">input data</span> and the <span style="text-decoration: underline;">visual sketch</span>, the goal is to create a <span style="text-decoration: underline;">visualization of the input data</span> such that all visual traces in the sketch are contained by the output visualization. We have created a separate <a href="benchmarks.html">benchmarks page</a> for navigating our benchmarks. Note that in our evaluation, we use visual traces randomly sampled from the full visual trace as the input (visual sketch) to the synthesizer as discussed in Section 6.2 in the paper. In the benchmark viewer, for each bechmark, we present one visual sketch sampled from the full trace.</p>
 
      <h2>Experiment 1</h2>

      <p> The fist set of experiments (Section 6.2) involve running our synthesis algorithm with different sizes of visual sketch to evaluate (1) the number of benchmarks can be sovled at different timeout and (2) the impact of size of visual sketch on the ranking. In the following, we show instructions to produce the result in Table 1 and Table 2 of our paper.
      </p>

      <h3>Instructions</h3>

      <h5>General Running Instruction</h5>

      <p>To run the symbolic reasoning tool on a dataset, first make sure you have a directory named <code>output</code> under the folder <code>falx-popl-snapshot</code> to store evaluation logs (it should come with the artifact). Then, proceed to the folder <code>falx-popl-snapshot/falx</code> and run the evaluation scriopt as follows: </p>

      <pre>
cd /falx-popl-snapshot/artifact/falx
bash full_eval.sh ALGORITHM NUM_SAMPLES TIMEOUT</pre>

      <p>The evaluation script requires you to provide (1) the synthesis algorithm name, (2) the number of samples in visual sketch, and (3) timeout. It will then run the corresponding algorithm under the given condition for each benchmark in our benchmark collection, and then create a new folder named <code>exp_ALGORITHM_NUM_SAMPLES_DATETIME</code> under the folder <code>/falx-popl-snapshot/output</code> (one output for each file). On average, each run of the evaluation script takes around 3-5 hours, depending on the choice of algorithm and the environment.</p>

      <h5>Running Instruction for Experiment 1</h5>

      <p>As mentioned in the begining of this section, we will run a set of experiments for the <span style="text-decoration: underline">falx</span>
        synthesis algorithm (our new bidirectional synthesis algorithm) with different sizes of visual sketch (i.e., different <code>$NUM_SAMPLES=4, 6, 8</code>) under 600 seconds timeout. To do so, we will run the following set of commands:</p> 

      <pre>
cd /falx-popl-snapshot/artifact/falx
bash full_eval.sh falx 4 600</pre>

      <pre>
cd /falx-popl-snapshot/artifact/falx
bash full_eval.sh falx 6 600</pre>

      <pre>
cd /falx-popl-snapshot/artifact/falx
bash full_eval.sh falx 8 600</pre>

      <p>When all of the three experiments finish, we are expected to see 3 new folders in the output directory <code>/falx-popl-snapshot/output</code>:</p>

      <ul> 
        <li><code>exp_falx_4_DATETIME1</code></li>
        <li><code>exp_falx_6_DATETIME2</code></li>
        <li><code>exp_falx_8_DATETIME3</code></li>
      </ul>

      <p>Note that DATETIME1, DATETIME2, DATETIME3 are the timestamps you run each experiment. Each file logs the following information of the benchmark: the input table it takes, the sample sketch used, whether the task completes, the synthesized table program / visualization script, and the time spent in finishing the synthesis task.</p>

      <h5>Analyzing Logs</h5>

      <p>After obtaining evaluation logs, we can run the analysis script to obtain the evaluation results reported in the paper (Table 1 and Table 2 in Section 6). Use the following command to run the analysis script:</p>

      <pre>
cd /falx-popl-snapshot/artifact/output
python plot_script_1.py exp_falx_4 exp_falx_6 exp_falx_8
      </pre>


      <h3>Remarks</h3>

      <p>The exact numbers in the result table may be different from ones reported in the paper due to the running platform difference. However, the number of benchmarks solved within each time limit should be consistent with those reported in the paper. If there are several benchmarks not solvable within 600 seconds timeout, you can increase the time limit a bit to retry that benchmark.</p>

      <p>We also provide raw logs generated during our evaluation in the <code>output</code> directory. We can run the analysis script to obtain the tables in the paper using the command shown in the last subsection, using the following commands:</p>

      <pre>TODO</pre>

      <pre>TODO</pre>

      <h2>Experiment 2 & 3</h2>

      <p> The second and the third experiments (Section 6.3, Section 6.4) are abalation studies of our synthesis algorithm. Experiment 2 (Section 6.3) compares the the falx synthesis algorithm with and without decomposition. Experiment 3 (Section 6.4) compares the pruning power of the bidirectional synthsis algorithm against <a href="https://arxiv.org/abs/1611.07502">the Morpheus algorithm</a> for the table transformation task. The instructions of running these two experiments also follow the general running instructions in the last section.
      </p>

      <h5>Running Instruction for Experiment 2</h5>

      <p>We will run a set of experiments for the standard falx algorithm that we have already run in Experiment 1, and a variation of the falx algorithm without synthesis decomposition (by setting ALGORITHM to <code>none</code>). Both experiments use <code>SAMPLE_SIZE=4</code> and <code>TIMEOUT=600</code> (seconds). Since we already have the result of runnig falx algorithhm with <code>SAMPLE_SIZE=4</code> and <code>TIMEOUT=600</code>, we only need to run one extra experiment using the following command:

      <pre>
cd /falx-popl-snapshot/falx;
bash full_eval.sh none 4 600;</pre>

       <p>When the experiment finish, one new folder will appear in the output directory <code>/falx-popl-snapshot/output</code>, namely <code>exp_none_4_DATETIME4</code>, where <code>DATETIME4</code> is the timestamp of the experiment.</p>

      <h5>Running Instruction for Experiment 3</h5>

      <p>We will run a set of experiments for the standard falx algorithm that we have already run in Experiment 1, and a modified falx synthesizer with the table synthesis algorithm replaced by the morepheus algorithm (by setting ALGORITHM to <code>morpheus</code>). Both cases use <code>SAMPLE_SIZE=4</code> and <code>TIMEOUT=600</code> seconds. Since we already have the result of runnig falx algorithhm with <code>SAMPLE_SIZE=4</code> and <code>TIMEOUT=600</code>, we only need to run one extra experiment using the following command:

      <pre>
cd /falx-popl-snapshot/falx;
bash full_eval.sh morpheus 4 600;</pre>

       <p>When the experiment finish, one new folder will appear in the output directory <code>/falx-popl-snapshot/output</code>, namely <code>exp_morpheus_4_DATETIME5</code>, where <code>DATETIME5</code> is the timestamp of the experiment.</p>

      <h5>Analyzing Logs</h5>

      <p>First check that the three folders <code>exp_falx_4_DATETIME1</code>, <code>exp_none_4_DATETIME4</code> and <code>exp_morpheus_4_DATETIME5</code> are under the output directory <code>/falx-popl-snapshot/output</code>. If so, we are ready to use the analysis script to reproduce the charts in Figure 14 in our paper.</p>

      <p>Note that our experiment in the paper was run on a 2.7 GHz Quad-Core Intel Core i7 processor with 16G memory. If running on a different processor, the absolute time spent in solving each benchmark may vary. However, the relative solving time should be consistent with Figure 14, even when running on a different processer.</p>

      <p>We also provide raw logs generated during our evaluation in the <code>output</code> directory. We can run the analysis script to obtain Table 14 in the paper using the following commands:</p>

      <pre>TODO</pre>

      <pre>TODO</pre>

      <h2>Contact</h2>

      <p>We would like to receive suggestions from you about further improving the artifact. Feel free to drop us a line.</p>
    </section>
  </div>
</body>
</html>
