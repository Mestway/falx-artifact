<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <title>Falx Artifact</title>

  <link rel="stylesheet" href="static/index.css">
  <link rel="stylesheet" href="static/github-light.css">
  <meta name="viewport" content="width=device-width">
</head>
<body>
  <div class="wrapper">
    <header>
      <h1>Visualization By Example</h1>
      <h3 class="subtitle">Chenglong Wang, Yu Feng, Ras Bodik, Alvin Cheung, Isil Dillig </h3>
    </header>

    <section>
      <p>This page hosts the artifact for our POPL 2020 submission, <a href="popl20_draft.pdf"><i>Visualization By Example (draft)</i></a>.
      </p>

      <h2>Materials</h2>

      <p>Our artifact contains the following materials: </p>

      <ul> 
        <li> <i>Benchmarks</i> of visualization by example tasks. See <a href="#benchmarks">Benchmarks</a> section.</li>
        <li> <i>Implementation of the synthesis algorithm</i> (named <span style="font-weight:bold;">Falx</span> under the <code>artifact</code> directory) in Python3. This is our implementation used in the paper evaluation.</li>
        <li> <i>Evaluation log and analysis scripts</i> used in our paper evaluation.</li>
        <li> <i>A new implementation of the synthesis algorithm</i> for playing purpose. See <a href="#extra">Extra: Play with the Tool</a> to learn about this new implementation.</li>
      </ul>

      <h2>Prerequisite</h2>

      <p>Our experiments run in Docker, instructions to install Docker can be found <a href="https://docs.docker.com/install/">here</a>.</p>

      <p>After the docker is install, run the following command to create and enter the Docker container that would be used for artifat evaluation. This command will download the docker image (this step takes around 20 minutes), build the docker container, and finally enter the docker container.</p>

      <pre>sh ./init_docker.sh</pre>

      <p>Once in the docker, run the following commands to install dependencies. These commands install python dependencies of our tool as well as setting the tool as a Python library itself.</p>

      <pre>cd /falx-popl-snapshot/artifact
pip3 install -r requirements.txt
pip3 install -e .</pre>

      <div style="background: lightyellow; padding: 10px 20px 0px 20px;">
        <p><span style="font-weight: bold;text-decoration:underline;">How to start over?</span> In an event that your docker building process get broken or you want to destroy your docker container and start over, you can delete the docker container using command <code>docker rm falx-artifact</code>, and then start over from the first step using <code>sh ./init_docker.sh</code>.
        </p>
        <p style="text-decoration: underline;">Make sure you re-run scripts to re-install all dependencies again after you rebuild the docker container.</p>

        <p>In a extremely rare event that that you want to destroy the docker image and strat over: use command <code>docker rmi falx-artifact-img</code> and then start again using <code>sh ./init_docker.sh</code>. However, we do not recommend this since re-dowloading the docker image would take quite a while to finish.</p>
      </div>

      <h2>Overview</h2>

      <p>
        Our implementation of the visualization synthesizer includes three main modules: (1) the implementation of the visualization language interpreter that interprets a Vega-Lite script into visualization trace (<a href="falx-popl-snapshot/falx/chart.py">link</a>), (2) an R table transformation language interpreter built on top of R tydiverse library (<a href="falx-popl-snapshot/falx/morpheus.py">link</a>), and (3) a bidirectional synthesizer that synthesizes visualization scripts from input data and partial visual trace, which is built on top of the Z3 SMT solver. We also include implementations of the baseline in our artifact to reproduce results in the paper.
      </p>

      <p>
        In the following, we first present benchmarks we used in our evaluation, then show instructions to reproduce our experiments described in the paper (Section 6), and finally how to use our the tool to solve new visualization tasks. 
      </p>

      <h2 id="benchmarks">Benchmarks</h2>

      <p>In our AutoVis benchmarks, each visual sketch comes with an input data. Given the <span style="text-decoration: underline;">input data</span> and the <span style="text-decoration: underline;">visual sketch</span>, the goal is to create a <span style="text-decoration: underline;">visualization of the input data</span> such that all visual traces in the sketch are contained by the output visualization. We have created a separate <a href="benchmarks.html">benchmarks page</a> for navigating our benchmarks. Note that in our evaluation, we use visual traces randomly sampled from the full visual trace as the input (visual sketch) to the synthesizer as discussed in Section 6.2 in the paper. In the benchmark viewer, for each bechmark, we present one visual sketch sampled from the full trace.</p>

      <h2>Experiment 1</h2>

      <p> The first set of experiments (Section 6.2) involve running our synthesis algorithm with different sizes of visual sketch to evaluate (1) the number of benchmarks can be sovled at different timeout and (2) the impact of visual sketch size on the ranking. In the following, we show instructions to produce the result in Table 1 and Table 2 of our paper.
      </p>

      <h3>General Running Instruction</h3>

      <p>To run the visualization by example experiment, first make sure you have a directory named <code>output</code> under the folder <code>falx-popl-snapshot</code> to store evaluation logs (it should come with the artifact). Then, run the evaluation script as follows: </p>

      <pre>
cd /falx-popl-snapshot/artifact/falx
bash full_eval.sh ALGORITHM NUM_SAMPLES TIMEOUT</pre>

      <p>The evaluation script requires you to provide (1) the synthesis algorithm name, (2) the number of samples in visual sketch, and (3) timeout. It will then run the corresponding algorithm under the given condition for each benchmark in our benchmark collection, and then create a new folder named <code>exp_ALGORITHM_NUM_SAMPLES_DATETIME</code> under the folder <code>/falx-popl-snapshot/artifact/output</code> (one output for each file). On average, each run of the evaluation script takes around 3-10 hours (for all 83 benchmarks), depending on  choice of the algorithm (baselines take longer time to finish) and the environment.</p>

      <h3>Running Instruction for Experiment 1</h3>

      <p>As mentioned in the begining of this section, we first run a set of experiments for the falx
        synthesis algorithm (our new bidirectional synthesis algorithm) with different visual sketch sample sizes (i.e., <code>NUM_SAMPLES=4, 6, 8</code>) under 600 seconds timeout. To do so, we will run the following set of commands:</p> 

      <pre>
cd /falx-popl-snapshot/artifact/falx
bash full_eval.sh falx 4 600</pre>

      <pre>
cd /falx-popl-snapshot/artifact/falx
bash full_eval.sh falx 6 600</pre>

      <pre>
cd /falx-popl-snapshot/artifact/falx
bash full_eval.sh falx 8 600</pre>

      <p>When all of the three experiments finish, we are expected to see 3 new folders in the output directory <code>/falx-popl-snapshot/artifact/output</code>:</p>

      <ul> 
        <li><code>exp_falx_4_new</code></li>
        <li><code>exp_falx_6_new</code></li>
        <li><code>exp_falx_8_new</code></li>
      </ul>

      <p>Each log file in a log folder corresponds to one benchmark in our dataset, and it stores the following information: the input table, the sample visual sketch, whether the task completes, the synthesized table program / visualization script, and the time spent in finishing the synthesis task. A log file may contain some error messages -- they are often errors encountered during executions of wrong synthesized programs, you can directly scroll to the bottom of the file to check the synthesis status.</p>

      <h3>Analyzing Logs</h3>

      <p>After obtaining evaluation logs, we can run the analysis script to obtain the evaluation results reported in the paper (Table 1 and Table 2 in Section 6). Use the following command to run the analysis script:</p>

      <pre>
cd /falx-popl-snapshot/artifact/output
python plot_script_1.py exp_falx_4_new
python plot_script_1.py exp_falx_6_new 
python plot_script_1.py exp_falx_8_new</pre>

      <p>For each execution log, the analysis script will perform the following two analysis tasks:

      <ol> 
        <li>it counts the number of cases such that the correct solution is ranked among top-1, top-5, top-10 of synthesized solutions as well as the total number of benchmarks solved by the synthesizer</li>
        <li>it counts the numbers of cases that can be solved within 1 / 10 / 60 / 600 seconds by the synthesizer</li>
      </ol> 

      The output should be of the following format:</p>

      <pre>
LOG_DIR
  # cases solved solved within top 1:  X1
  # cases solved solved within top 5:  X2
  # cases solved solved within top 10: X3
  # cases solved within time limit:    X4
---
  # caes solved within 1 second(s): Y1
  # caes solved within 10 second(s): Y2
  # caes solved within 60 second(s): Y3
  # caes solved within 600 second(s): Y4</pre>

      <p>LOG_DIR is the experiment log folder name and X1 / X2 / X3 / X4 / Y1 / Y2 / Y3 / Y4 should be numbers that are consistent with Table 1 and Table 2 in the paper:
      <ol> 
        <li>The result of Table 1 should be consistent with the second part of the output from command <code>python plot_script_1.py exp_falx_4_new</code></li>
        <li>The result of Table 2 should be consistent with the first part of the outputs from the analysis scripts (<code>python plot_script_1.py exp_falx_4_new;python plot_script_1.py exp_falx_6_new; python plot_script_1.py exp_falx_8_new;</code>) </li>
      </ol> 
    </p>

      <div class="remarks">
      <h3>Remarks</h3>

      <p>Note that our experiment in the paper was run on a 2.7 GHz Quad-Core Intel Core i7 processor with 16G memory. The exact numbers in the result table may be different from ones reported in the paper due to the running platform difference. However, the number of benchmarks solved within each time limit should be consistent with those reported in the paper. If there are several benchmarks not solvable within 600 seconds timeout, you can increase the time limit a bit to retry on failed benchmarks. (We also observe this difference when running on different platforms, since several slow cases take around 300-500 seconds to finish, which may fail to finish within 600 seconds if the running environment is different.)</p>

      <p>We also provide raw logs produced by our experiment run for paper submission in the <code>output</code> directory (namely, <code>exp_falx_4</code>, <code>exp_falx_6</code>, <code>exp_falx_8</code>). We can run the following analysis script to obtain the tables in the paper:</p>

      <pre>
cd /falx-popl-snapshot/artifact/output
python plot_script_1.py exp_falx_4
python plot_script_1.py exp_falx_6 
python plot_script_1.py exp_falx_8</pre>

      <p>This will reproduce the result in Table 1 and Table 2 in the paper.</p>

    </div>

      <h2>Experiment 2 & 3</h2>

      <p> The second and the third experiments (Section 6.3, Section 6.4) are abalation studies of our synthesis algorithm. Experiment 2 (Section 6.3) compares the the falx synthesis algorithm with and without decomposition. Experiment 3 (Section 6.4) compares the pruning power of the bidirectional synthsis algorithm against <a href="https://arxiv.org/abs/1611.07502">the Morpheus algorithm</a> for the table transformation task. The instructions of running these two experiments also follow the general running instructions in the last section.
      </p>

      <h3>Running Instruction for Experiment 2</h3>

      <p>We will run a set of experiments for the standard falx algorithm that we have already run in Experiment 1, and a variation of the falx algorithm without synthesis decomposition (by setting ALGORITHM to <code>none</code>). Both experiments use <code>SAMPLE_SIZE=4</code> and <code>TIMEOUT=600</code> (seconds). Since we already have the result of runnig falx algorithhm with <code>SAMPLE_SIZE=4</code> and <code>TIMEOUT=600</code>, we only need to run one extra experiment using the following command:

      <pre>
cd /falx-popl-snapshot/artifact/falx
bash full_eval.sh none 4 600</pre>

       <p>When the experiment finish, one new folder will appear in the output directory <code>/falx-popl-snapshot/artifact/output</code>, namely <code>exp_none_4_new</code>, where <code>new</code> is the timestamp of the experiment.</p>

       <p><span style="font-weight: bold;text-decoration:underline;">What to do if the computer get stuck on one benchmark?</span> Sometimes, the timeout command may not successfully terminate the program after the timeout is hit. In this event, you can terminate the current evaluation run manually and re-run the evaluation script. Note that our script is made in the way such that finished benchmarks (i.e., if the corresponding log file already exists in the output directory) won't be re-run. So, you can feel free to interrupt the script in the running process if one benchmark takes too long (longer than the timeout) and re-run the script. You can even destroy the docker container and start over, it won't waste time on finished benchmarks (but it will spend extra time in building the container and setting up dependencies).</p>

      <h3>Running Instruction for Experiment 3</h3>

      <p>We will run a set of experiments for the standard falx algorithm that we have already run in Experiment 1, and a modified falx synthesizer with the table synthesis algorithm replaced by the morepheus algorithm (by setting ALGORITHM to <code>morpheus</code>). Both cases use <code>SAMPLE_SIZE=4</code> and <code>TIMEOUT=600</code> seconds. Since we already have the result of runnig falx algorithhm with <code>SAMPLE_SIZE=4</code> and <code>TIMEOUT=600</code>, we only need to run one extra experiment using the following command:

      <pre>
cd /falx-popl-snapshot/artifact/falx
bash full_eval.sh morpheus 4 600</pre>

       <p>When the experiment finish, one new folder will appear in the output directory <code>/falx-popl-snapshot/artifact/output</code>, namely <code>exp_morpheus_4_new</code>, where <code>new</code> is the timestamp of the experiment.</p>

      <h3>Analyzing Logs</h3>

      <p>First check that the three folders <code>exp_falx_4_new</code>, <code>exp_none_4_new</code> and <code>exp_morpheus_4_new</code> are under the output directory <code>/falx-popl-snapshot/artifact/output</code>. If so, we are ready to use the following analysis scripts to reproduce the charts in Figure 14 in our paper.</p>

      <pre>cd /falx-popl-snapshot/artifact/output
python plot_script_2.py exp_falx_4_new exp_none_4_new</pre>
      
      <p>Note that the output of analysis script will be a long one line string (that will be unreadable), to create the visualization, copy the output string to <a href="https://vega.github.io/editor/#/custom/vega-lite">Vega-Lite online editor</a> and view the visualization. The result of this experiment should be consistent with Figure 14(a) in the paper.</p>

      <p>Similarly, use the following sript to get the comparison result between falx and the morpheus variant:</p>
      <pre>cd /falx-popl-snapshot/artifact/output
python plot_script_2.py exp_falx_4_new exp_morpheus_4_new</pre>

      <p>Copy the output string to <a href="https://vega.github.io/editor/#/custom/vega-lite">Vega-Lite online editor</a> and view the visualization. The result of this experiment should be consistent with Figure 14(b) in the paper.</p>

      <div class="remarks">
        <h3>Remarks</h3>

        <p>Note that our experiment in the paper was run on a 2.7 GHz Quad-Core Intel Core i7 processor with 16G memory. If running on a different processor, the absolute time spent in solving each benchmark may vary. However, the relative solving time should be consistent with Figure 14, even when running on a different processer.</p>

        <p>We also provide raw logs generated during our evaluation in the <code>output</code> directory. We can run the analysis script to obtain Table 14 in the paper using the following commands:</p>

        <pre>cd /falx-popl-snapshot/artifact/output
  python plot_script_2.py exp_falx_4 exp_none_4_all</pre>

        <pre>cd /falx-popl-snapshot/artifact/output
  python plot_script_2.py exp_falx_4 exp_morpheus_4</pre>

        <p>Copy output (one at a time) to <a href="https://vega.github.io/editor/#/custom/vega-lite">Vega-Lite online editor</a> to reproduce the two charts in Figure 14.</p>

      </div>

      <h2 id="extra">Extra: Play with the Tool</h2>

      <p>Last, we will play with the tool to experiment with solving new benchmarks outside of our evaluation dataset. In this section, we will use our newest version of the synthesis tool (<a href="./falx-artifact/falx-new">falx-artifact/falx-new</a>) to solve visualization by example tasks. Unlike the previous tool we used in reproducing evaluation result, this tool won't try to sample visual sketch from the full visual trace, but instead ask the user to directly provide both input table and the visual trace to the interface. Also, this new implementation is more up-to-date than the popl snapshot version, with some improvement in the synthesis algorithm implementation.</p>
      
      <p>To use the tool, create a json file containing the input table and the visual sketch similar to the following example:</p>

      <pre>
{
  "input_data": [
    { "Bucket": "Bucket E", "Budgeted": 100, "Actual": 115 },
    { "Bucket": "Bucket D", "Budgeted": 100, "Actual": 90 },
    { "Bucket": "Bucket C", "Budgeted": 125, "Actual": 115 },
    { "Bucket": "Bucket B", "Budgeted": 125, "Actual": 140 },
    { "Bucket": "Bucket A", "Budgeted": 140, "Actual": 150 }
  ],
  "raw_trace": [
    {"type": "bar", "props": { "x": "Actual", "y": 115,  "color": "Actual", "column": "Bucket E"}},
    {"type": "bar", "props": { "x": "Actual", "y": 90,"color": "Actual", "column": "Bucket D"}},
    {"type": "bar", "props": { "x": "Budgeted","y": 100,  "color": "Budgeted", "column": "Bucket D"}}
  ]
}</pre>

      <p>In this example, the input table is a json-dict representation of an input table, where each tuple in the list represent a row in the table. Each key-value map indicates the value for the corresponding column (e.g., <code>"Bucket": "Bucket E"</code> indicates that the value of column <code>Bucket</code> in the first row is <code>Bucket E</code>). The visual sketch is a list of trace elements specifying what elements will appear on the canvas. You can refer to <a href="benchmarks.html">benchmarks page</a> to check supported grammar for the visual trace (note that some properties may not be available for some element types).</p>

      <p>Besides the example above, we have created multiple basic visualization examples in <a href="falx-new/examples/">the examples folder</a>.</p>
      
      <h3>Runing Instruction</h3>

      <p>In order to run the example, we will first need to setup the tool using the follow command:</p>

      <pre>cd /falx-popl-snapshot/falx-new
pip3 install -e .
</pre>
      
      <p>This command will install the current tool to the system path. Note that if you would like to switch back to the popl snapshot version for reproducing paper experiments, you will need to run the following commands to set up the popl implementation again: <code>cd /falx-popl-snapshot/artifact;pip3 install -e .;</code>.</p>

      <p>Once this is correctly set up, use the following command to run the synthesizer:</p>
      <pre>cd /falx-popl-snapshot/falx-new/falx
python run.py --input_file=INPUT_FILE --output_file=OUTPUT_FILE
</pre>
      
      <p>The <code>INPUT_FILE</code> should be the input json file containing input table and visual sketch (e.g., the file <code>/falx-popl-snapshot/falx-new/examples/example-1.json</code>), and the <code>OUTPUT_FILE</code> is the output visualization script.</p>

      <p>To visualize the synthesized visualization, copy the content in the output visualization script and paste it into <a href="https://vega.github.io/editor/#/custom/vega-lite">Vega-Lite online editor</a>. It should render the visualization for you.</p>

      <p><span style="font-weight: bold">Example</span> Below we show the example command to run  <code>example-1.json</code>:</p>
      <pre>cd /falx-popl-snapshot/falx-new
pip3 install -e .
cd /falx-popl-snapshot/falx-new/falx
python run.py --input_file=/falx-popl-snapshot/falx-new/examples/example-1.json --output_file=/falx-popl-snapshot/falx-new/examples/example-1-output.json
</pre>
      <p>You can then copy the content in <code>/falx-popl-snapshot/falx-new/examples/example-1-output.json</code> to <a href="https://vega.github.io/editor/#/custom/vega-lite">Vega-Lite online editor</a> to view the synthesized visualization.</p>

      <h2>Contact</h2>

      <p>We would like to receive suggestions from you about further improving the artifact. Feel free to drop us a line.</p>
    </section>
  </div>
</body>
</html>
